# Image_Captioning_project

Caption generation is a challenging artificial intelligence problem where a textual description must be generated for a given photograph.

It requires both methods from computer vision to understand the content of the image and a language model from the field of natural language processing to turn the understanding of the image into words in the right order.

This Project is divided into 6 parts; they are:

1)Photo and Caption Dataset

2)Prepare Photo Data

3)Prepare Text Data

4)Develop Deep Learning Model

5)Train With Progressive Loading (NEW)

6)Evaluate Model

7)Generate New Captions

##Photo and Caption Dataset

A good dataset to use when getting started with image captioning is the Flickr8K dataset.

The reason is because it is realistic and relatively small so that you can download it and build models on your workstation using a CPU.

The definitive description of the dataset is in the paper “Framing Image Description as a Ranking Task: Data, Models and Evaluation Metrics” from 2013
